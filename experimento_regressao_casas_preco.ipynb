{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "experimento_regressao_casas_preco.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pedroAndrad1/regression_experiments/blob/master/experimento_regressao_casas_preco.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKU6Xs3NTrur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Nao tem o dataset online, baixei e salvei no meu drive.\n",
        "#To pegando o arquivo aqui.\n",
        "#Esse algoritmo ta no code snippet em insert. \n",
        "\n",
        "#Vai precisar fazer isso tambem\n",
        "#Baixa o csv, upa no seu drive, e coloca em file_id o id que tiver no arquivo.\n",
        "\n",
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Download a file based on its file ID.\n",
        "#\n",
        "# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
        "file_id = '1GEPSGJFtZfSqozdfHNnnrDEFNODDODYW'\n",
        "downloaded= drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('kc_house_data.csv') #Essa linha nao esta no snippet, aqui e pra de fato pegar o csv."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYsevxJMXT0k",
        "colab_type": "text"
      },
      "source": [
        "#Legenda das colunas do dataset\n",
        "\n",
        "id: notation for a house\n",
        "\n",
        "date: Date house was sold\n",
        "\n",
        "price: Price is prediction target\n",
        "\n",
        "bedrooms: Number of Bedrooms/House\n",
        "\n",
        "bathrooms: Number of bathrooms/House\n",
        "\n",
        "sqft_living: square footage of the home\n",
        "\n",
        "sqft_lots: quare footage of the lot\n",
        "\n",
        "floors: Total floors (levels) in house\n",
        "\n",
        "waterfront: House which has a view to a waterfront\n",
        "\n",
        "view: Has been viewed\n",
        "\n",
        "condition: How good the condition is ( Overall )\n",
        "\n",
        "grade: overall grade given to the housing unit, based on King County grading system\n",
        "\n",
        "sqft_above: square footage of house apart from basement\n",
        "\n",
        "sqft_basement: square footage of the basement\n",
        "\n",
        "yr_built: Built Year\n",
        "\n",
        "yr_renovated: Year when house was renovated\n",
        "\n",
        "zipcode: zip\n",
        "\n",
        "lat: Latitude coordinate\n",
        "\n",
        "long: Longitude coordinate\n",
        "\n",
        "sqft_living15: Living room area in 2015(implies-- some renovations) This might or might not have affected the lotsize area\n",
        "\n",
        "sqft_lot15: lotSize area in 2015(implies-- some renovations)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVvS0PHCUyRU",
        "colab_type": "code",
        "outputId": "1b3a4024-aa09-4ef4-cdb6-a3728a7280a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "import pandas as pd\n",
        "#Lendo o csv para um dataframe com o pandas.\n",
        "\n",
        "casas_data = pd.read_csv('kc_house_data.csv')\n",
        "\n",
        "casas_data.head()\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>price</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>sqft_living</th>\n",
              "      <th>sqft_lot</th>\n",
              "      <th>floors</th>\n",
              "      <th>waterfront</th>\n",
              "      <th>view</th>\n",
              "      <th>condition</th>\n",
              "      <th>grade</th>\n",
              "      <th>sqft_above</th>\n",
              "      <th>sqft_basement</th>\n",
              "      <th>yr_built</th>\n",
              "      <th>yr_renovated</th>\n",
              "      <th>zipcode</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>sqft_living15</th>\n",
              "      <th>sqft_lot15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7129300520</td>\n",
              "      <td>20141013T000000</td>\n",
              "      <td>221900.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1180</td>\n",
              "      <td>5650</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1180</td>\n",
              "      <td>0</td>\n",
              "      <td>1955</td>\n",
              "      <td>0</td>\n",
              "      <td>98178</td>\n",
              "      <td>47.5112</td>\n",
              "      <td>-122.257</td>\n",
              "      <td>1340</td>\n",
              "      <td>5650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6414100192</td>\n",
              "      <td>20141209T000000</td>\n",
              "      <td>538000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.25</td>\n",
              "      <td>2570</td>\n",
              "      <td>7242</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>2170</td>\n",
              "      <td>400</td>\n",
              "      <td>1951</td>\n",
              "      <td>1991</td>\n",
              "      <td>98125</td>\n",
              "      <td>47.7210</td>\n",
              "      <td>-122.319</td>\n",
              "      <td>1690</td>\n",
              "      <td>7639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5631500400</td>\n",
              "      <td>20150225T000000</td>\n",
              "      <td>180000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>770</td>\n",
              "      <td>10000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>770</td>\n",
              "      <td>0</td>\n",
              "      <td>1933</td>\n",
              "      <td>0</td>\n",
              "      <td>98028</td>\n",
              "      <td>47.7379</td>\n",
              "      <td>-122.233</td>\n",
              "      <td>2720</td>\n",
              "      <td>8062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2487200875</td>\n",
              "      <td>20141209T000000</td>\n",
              "      <td>604000.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3.00</td>\n",
              "      <td>1960</td>\n",
              "      <td>5000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>1050</td>\n",
              "      <td>910</td>\n",
              "      <td>1965</td>\n",
              "      <td>0</td>\n",
              "      <td>98136</td>\n",
              "      <td>47.5208</td>\n",
              "      <td>-122.393</td>\n",
              "      <td>1360</td>\n",
              "      <td>5000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1954400510</td>\n",
              "      <td>20150218T000000</td>\n",
              "      <td>510000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.00</td>\n",
              "      <td>1680</td>\n",
              "      <td>8080</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>1680</td>\n",
              "      <td>0</td>\n",
              "      <td>1987</td>\n",
              "      <td>0</td>\n",
              "      <td>98074</td>\n",
              "      <td>47.6168</td>\n",
              "      <td>-122.045</td>\n",
              "      <td>1800</td>\n",
              "      <td>7503</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id             date     price  ...     long  sqft_living15  sqft_lot15\n",
              "0  7129300520  20141013T000000  221900.0  ... -122.257           1340        5650\n",
              "1  6414100192  20141209T000000  538000.0  ... -122.319           1690        7639\n",
              "2  5631500400  20150225T000000  180000.0  ... -122.233           2720        8062\n",
              "3  2487200875  20141209T000000  604000.0  ... -122.393           1360        5000\n",
              "4  1954400510  20150218T000000  510000.0  ... -122.045           1800        7503\n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIqocz6QYjQU",
        "colab_type": "text"
      },
      "source": [
        "OK, vou dropar as seguintes colunas: id, date e zipcode. Julguei desnecessarias.\n",
        "Também vou dropar as colunas sqft_lot e sqft_living. Pois esses valores estão atualizados nas colunas sqft_lot15 e sqft_living15."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHGVNoKIVZQO",
        "colab_type": "code",
        "outputId": "36c51624-bde0-4c2b-cd32-324ec9bd3bbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "#A funcao drop retorna um novo dataframe.\n",
        "#O parametro axis e para dropar a coluna, o default e linha.\n",
        "casas_data = casas_data.drop( ['id', 'date', 'zipcode', 'sqft_living', 'sqft_lot'] , axis = 'columns' )\n",
        "casas_data.head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>floors</th>\n",
              "      <th>waterfront</th>\n",
              "      <th>view</th>\n",
              "      <th>condition</th>\n",
              "      <th>grade</th>\n",
              "      <th>sqft_above</th>\n",
              "      <th>sqft_basement</th>\n",
              "      <th>yr_built</th>\n",
              "      <th>yr_renovated</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>sqft_living15</th>\n",
              "      <th>sqft_lot15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>221900.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1180</td>\n",
              "      <td>0</td>\n",
              "      <td>1955</td>\n",
              "      <td>0</td>\n",
              "      <td>47.5112</td>\n",
              "      <td>-122.257</td>\n",
              "      <td>1340</td>\n",
              "      <td>5650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>538000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.25</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>2170</td>\n",
              "      <td>400</td>\n",
              "      <td>1951</td>\n",
              "      <td>1991</td>\n",
              "      <td>47.7210</td>\n",
              "      <td>-122.319</td>\n",
              "      <td>1690</td>\n",
              "      <td>7639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>180000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>770</td>\n",
              "      <td>0</td>\n",
              "      <td>1933</td>\n",
              "      <td>0</td>\n",
              "      <td>47.7379</td>\n",
              "      <td>-122.233</td>\n",
              "      <td>2720</td>\n",
              "      <td>8062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>604000.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>1050</td>\n",
              "      <td>910</td>\n",
              "      <td>1965</td>\n",
              "      <td>0</td>\n",
              "      <td>47.5208</td>\n",
              "      <td>-122.393</td>\n",
              "      <td>1360</td>\n",
              "      <td>5000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>510000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>1680</td>\n",
              "      <td>0</td>\n",
              "      <td>1987</td>\n",
              "      <td>0</td>\n",
              "      <td>47.6168</td>\n",
              "      <td>-122.045</td>\n",
              "      <td>1800</td>\n",
              "      <td>7503</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      price  bedrooms  bathrooms  ...     long  sqft_living15  sqft_lot15\n",
              "0  221900.0         3       1.00  ... -122.257           1340        5650\n",
              "1  538000.0         3       2.25  ... -122.319           1690        7639\n",
              "2  180000.0         2       1.00  ... -122.233           2720        8062\n",
              "3  604000.0         4       3.00  ... -122.393           1360        5000\n",
              "4  510000.0         3       2.00  ... -122.045           1800        7503\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktHvLc4iavqy",
        "colab_type": "text"
      },
      "source": [
        "Vou splitar o dataframe em treino e teste e reescalar os valores das features, tem valores na casas dos milhares e outros na casa das dezenas. \n",
        "\n",
        "Usarei o StandardScaler do módulo preprocessing da bilbioteca sklearn para reescalar as features e o train_test_split do módulo model_selection do sklearn para splitar.\n",
        "\n",
        "Tanto faz a ordem, pois o train_test_split aceita tanto um pandas dataframe quanto um array como paramêtro.\n",
        "\n",
        "docs:\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler.fit_transform\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
        "\n",
        "https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.seed.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JicXpaMPvdE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "#Os random_state chamam essa funcao por debaixo dos panos.\n",
        "#Setando isso aqui, nao preciso colocar o random_state pra tudo que for fazer.\n",
        "np.random.seed(0) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIFAlzQ6pzoE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#Vou separar logo o dataframe em x e y, features e classes.\n",
        "\n",
        "x = casas_data[ ['bedrooms', 'bathrooms', 'floors', 'waterfront', 'view', 'condition', 'grade',\n",
        "               'sqft_above','sqft_basement','yr_built', 'yr_renovated', 'lat',\n",
        "               'long', 'sqft_living15', 'sqft_lot15'] ]\n",
        "y = casas_data['price']\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "#Como existem multiplos valores de y, nao faz sentido extratificar.\n",
        "\n",
        "x_treino, x_teste, y_treino, y_teste = train_test_split(x, y)\n",
        "\n",
        "#Reescalando as features\n",
        "scaler = StandardScaler()\n",
        "x_treino_s = scaler.fit_transform(x_treino , y = y)\n",
        "x_teste_s = scaler.fit_transform(x_teste, y = y)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VHJP_slw0Yd",
        "colab_type": "text"
      },
      "source": [
        "Vou usar um dummy do sklearn para ser nosso modelo de baseline\n",
        "\n",
        "doc:\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyRegressor.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83MOKj_5wz65",
        "colab_type": "code",
        "outputId": "9d3befb5-560f-4977-cc19-c0353c5e0733",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.dummy import DummyRegressor\n",
        "\n",
        "#O Dummy tem varias maneiras de fazer os predict's.\n",
        "#Vou escolher dois e ver qual tem a maior acuracia.\n",
        "#Esse sera o baseline\n",
        "\n",
        "dummy_mean= DummyRegressor(strategy = \"mean\")\n",
        "dummy_median = DummyRegressor(strategy = \"median\")\n",
        "\n",
        "#Treinando os dummies\n",
        "\n",
        "dummy_mean.fit(x_treino_s, y_treino)\n",
        "dummy_median.fit(x_treino_s, y_treino)\n",
        "\n",
        "#Vendo as acuracias\n",
        "\n",
        "acuracia_mean = dummy_mean.score(x_teste_s, y_teste)\n",
        "acuracia_median = dummy_median.score(x_teste_s, y_teste)\n",
        "\n",
        "print(acuracia_mean)\n",
        "print(acuracia_median)\n",
        "\n",
        "#A documentacao diz que poder dar negativo, mas nao entendi oq isso significa.\n",
        "#Bom, de acordo com a documentacao, quanto mais perto de um melhor.\n",
        "#Logo, o baseline seria uma acuracia de 0. \n",
        "#Muito estranho, esperava um numero positivo."
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-0.0003331762965164131\n",
            "-0.05135901001470456\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fN_7kGdnHlIV",
        "colab_type": "text"
      },
      "source": [
        "Vou tentar fazer sem escalar as features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVNYBYWsG9vK",
        "colab_type": "code",
        "outputId": "de4f4393-ba5e-473e-bf2c-0e5b4707925b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "dummy_mean= DummyRegressor(strategy = \"mean\")\n",
        "dummy_median = DummyRegressor(strategy = \"median\")\n",
        "\n",
        "#Treinando os dummies\n",
        "\n",
        "dummy_mean.fit(x_treino, y_treino)\n",
        "dummy_median.fit(x_treino, y_treino)\n",
        "\n",
        "#Vendo as acuracias\n",
        "\n",
        "acuracia_mean = dummy_mean.score(x_teste, y_teste)\n",
        "acuracia_median = dummy_median.score(x_teste, y_teste)\n",
        "\n",
        "print(acuracia_mean)\n",
        "print(acuracia_median)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-0.0003331762965164131\n",
            "-0.05135901001470456\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1b-DKZeJOLB",
        "colab_type": "text"
      },
      "source": [
        "Ok, o resultado continua negativo. Bom, vou manter com as features escaladas.\n",
        "\n",
        "Nosso baseline será de 0%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Kt9pzB9J5MA",
        "colab_type": "text"
      },
      "source": [
        "Depois desses resultados peculiares, vou fazer a regressão com a classe LinearRegression.\n",
        "\n",
        "A gente pode tentar outras classes de regressão depois:\n",
        "\n",
        "Aqui uma lista, olha no módulo de linear_model:\n",
        "\n",
        "https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model\n",
        "\n",
        "Aqui o doc do LinearRegression:\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbhcUuJTKGGN",
        "colab_type": "code",
        "outputId": "218837f6-5385-4af0-84f1-1b356edeeddf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "modelo_linear = LinearRegression()\n",
        "\n",
        "modelo_linear.fit(x_treino_s, y_treino)\n",
        "modelo_linear.score(x_teste_s, y_teste)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6831635470401054"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mo4RsTRMyyj",
        "colab_type": "text"
      },
      "source": [
        "Olha só, em torno de 68% de acurácia em um número até expressivo.\n",
        "Eu estava muito recesoso do que iria sair dai kk.\n",
        "\n",
        "Plotar curva de aprendizado a baixo. A fazer\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-81mNLgBgXA0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwKM-Fz-gAwy",
        "colab_type": "text"
      },
      "source": [
        "Vamos testar agora com outros modelos.\n",
        "\n",
        "Vou testar agora com o LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gmx47mxvNwYM",
        "colab_type": "code",
        "outputId": "159f50f1-d146-4c2f-845c-80bc8ae8a60b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "modelo_logistico = LogisticRegression(solver = \"lbfgs\")\n",
        "\n",
        "modelo_logistico.fit(x_treino_s, y_treino)\n",
        "modelo_logistico.score(x_teste_s, y_teste)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-efc0edc5885e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodelo_logistico\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"lbfgs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodelo_logistico\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_treino\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_treino\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmodelo_logistico\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_teste\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_teste\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1604\u001b[0m                       \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1605\u001b[0m                       sample_weight=sample_weight)\n\u001b[0;32m-> 1606\u001b[0;31m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[1;32m   1607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1608\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    942\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfprime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 944\u001b[0;31m                 iprint=iprint, pgtol=tol, maxiter=max_iter)\n\u001b[0m\u001b[1;32m    945\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"warnflag\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m                 warnings.warn(\"lbfgs failed to converge. Increase the number \"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[0;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[0;32m--> 199\u001b[0;31m                            **opts)\n\u001b[0m\u001b[1;32m    200\u001b[0m     d = {'grad': res['jac'],\n\u001b[1;32m    201\u001b[0m          \u001b[0;34m'task'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36m_logistic_loss_and_grad\u001b[0;34m(w, X, y, alpha, sample_weight)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0mz0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;31m# Case where we fit the intercept.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzOvxLrIUbxG",
        "colab_type": "text"
      },
      "source": [
        "O LogisticRegression além de demorar muito, tem uma acurácia horrível.\n",
        "\n",
        "Vou testar agora, o LogisticRegressionCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zO7kZ_tWUuQQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "\n",
        "modelo_logistico_cv = LogisticRegression(solver = \"lbfgs\")\n",
        "\n",
        "modelo_logistico_cv.fit(x_treino_s, y_treino)\n",
        "modelo_logistico_cv.score(x_teste_s, y_teste)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnEF366bVy7f",
        "colab_type": "text"
      },
      "source": [
        "Horrivel também. Regressão logística realmente não é o caminho.\n",
        "\n",
        "Vou tentar a DecisonTreeRegressor.\n",
        "\n",
        "Docs: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\n",
        "\n",
        "Uma coisa legal de árvore de decisão é que ela trabalha bem com valores fora de escala.\n",
        "Por isso, vou usar os valores fora de escala. Fica melhor para plotar  a árvore de decisão depois."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JU9Zjh_hXcAJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "add8f383-e2d1-4404-9b7a-356115367923"
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "tree = DecisionTreeRegressor(max_depth = 9 )\n",
        "\n",
        "tree.fit(x_treino_s, y_treino)\n",
        "tree.score(x_teste_s, y_teste)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.779102531827673"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThVUhR8dX_hO",
        "colab_type": "text"
      },
      "source": [
        "A acuracia muda em função da altura máxima da árvore.\n",
        "\n",
        "*   Sendo 3, a acurácia fica por volta de 55%. O que não é melhor que o LinearRegressor\n",
        "*   De 5 em diante, a acurácia fica na casa de 70%.\n",
        "*   A profundidade igual a 9 se provou a com melhor acurácia, 78%. Mas a visualização da árvore de decisão fica muito ruim.\n",
        "\n",
        "A profundidade máxima para melhor visualizção da árvore de decisão é igual a 3.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvlF5fErX_kj",
        "colab_type": "text"
      },
      "source": [
        "Vou plotar a árvore de decisão.\n",
        "\n",
        "Usarei o export_graphviz do mesmo módulo da DecisionTreeRegressor para exportar as informções para plotagem e usarei o a biblioteca graphviz para plotar a partir das informações.\n",
        "\n",
        "docs:\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\n",
        "\n",
        "https://graphviz.readthedocs.io/en/stable/api.html#source\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ib7NKGBlYJMH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 654
        },
        "outputId": "aefd3e61-e45b-4207-faa0-e837099038fb"
      },
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "import graphviz\n",
        "\n",
        "features = x.columns\n",
        "\n",
        "dot_data = export_graphviz(tree, feature_names = features,\n",
        "                           filled = True, rounded = True, max_depth = 3)\n",
        "\n",
        "arvore_de_decisao = graphviz.Source(dot_data)\n",
        "arvore_de_decisao\n"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7fcc21227518>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"1597pt\" height=\"460pt\"\n viewBox=\"0.00 0.00 1596.50 460.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 456)\">\n<title>Tree</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-456 1592.5,-456 1592.5,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<path fill=\"#fef8f4\" stroke=\"#000000\" d=\"M844,-452C844,-452 689,-452 689,-452 683,-452 677,-446 677,-440 677,-440 677,-396 677,-396 677,-390 683,-384 689,-384 689,-384 844,-384 844,-384 850,-384 856,-390 856,-396 856,-396 856,-440 856,-440 856,-446 850,-452 844,-452\"/>\n<text text-anchor=\"middle\" x=\"766.5\" y=\"-436.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">grade &lt;= 0.714</text>\n<text text-anchor=\"middle\" x=\"766.5\" y=\"-421.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 135410380053.31</text>\n<text text-anchor=\"middle\" x=\"766.5\" y=\"-406.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 16209</text>\n<text text-anchor=\"middle\" x=\"766.5\" y=\"-391.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 541751.565</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<path fill=\"#fefaf7\" stroke=\"#000000\" d=\"M648,-348C648,-348 493,-348 493,-348 487,-348 481,-342 481,-336 481,-336 481,-292 481,-292 481,-286 487,-280 493,-280 493,-280 648,-280 648,-280 654,-280 660,-286 660,-292 660,-292 660,-336 660,-336 660,-342 654,-348 648,-348\"/>\n<text text-anchor=\"middle\" x=\"570.5\" y=\"-332.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">lat &lt;= &#45;0.195</text>\n<text text-anchor=\"middle\" x=\"570.5\" y=\"-317.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 38868828100.445</text>\n<text text-anchor=\"middle\" x=\"570.5\" y=\"-302.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 13019</text>\n<text text-anchor=\"middle\" x=\"570.5\" y=\"-287.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 439197.86</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M702.3223,-383.9465C683.6245,-374.0252 663.0544,-363.1105 643.8375,-352.9138\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"645.2959,-349.7255 634.8219,-348.13 642.0149,-355.9089 645.2959,-349.7255\"/>\n<text text-anchor=\"middle\" x=\"642.1517\" y=\"-368.3314\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n</g>\n<!-- 426 -->\n<g id=\"node17\" class=\"node\">\n<title>426</title>\n<path fill=\"#fcf1e9\" stroke=\"#000000\" d=\"M1053.5,-348C1053.5,-348 889.5,-348 889.5,-348 883.5,-348 877.5,-342 877.5,-336 877.5,-336 877.5,-292 877.5,-292 877.5,-286 883.5,-280 889.5,-280 889.5,-280 1053.5,-280 1053.5,-280 1059.5,-280 1065.5,-286 1065.5,-292 1065.5,-292 1065.5,-336 1065.5,-336 1065.5,-342 1059.5,-348 1053.5,-348\"/>\n<text text-anchor=\"middle\" x=\"971.5\" y=\"-332.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">grade &lt;= 2.413</text>\n<text text-anchor=\"middle\" x=\"971.5\" y=\"-317.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 311315153896.213</text>\n<text text-anchor=\"middle\" x=\"971.5\" y=\"-302.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3190</text>\n<text text-anchor=\"middle\" x=\"971.5\" y=\"-287.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 960292.844</text>\n</g>\n<!-- 0&#45;&gt;426 -->\n<g id=\"edge16\" class=\"edge\">\n<title>0&#45;&gt;426</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M833.6247,-383.9465C853.2695,-373.9803 874.8904,-363.0117 895.0677,-352.7754\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"896.89,-355.7756 904.2245,-348.13 893.723,-349.533 896.89,-355.7756\"/>\n<text text-anchor=\"middle\" x=\"896.4574\" y=\"-368.1928\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<path fill=\"#fefcfa\" stroke=\"#000000\" d=\"M356,-244C356,-244 201,-244 201,-244 195,-244 189,-238 189,-232 189,-232 189,-188 189,-188 189,-182 195,-176 201,-176 201,-176 356,-176 356,-176 362,-176 368,-182 368,-188 368,-188 368,-232 368,-232 368,-238 362,-244 356,-244\"/>\n<text text-anchor=\"middle\" x=\"278.5\" y=\"-228.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">sqft_living15 &lt;= &#45;0.176</text>\n<text text-anchor=\"middle\" x=\"278.5\" y=\"-213.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 14145881735.993</text>\n<text text-anchor=\"middle\" x=\"278.5\" y=\"-198.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 5345</text>\n<text text-anchor=\"middle\" x=\"278.5\" y=\"-183.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 314467.655</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M480.906,-282.0898C448.3293,-270.4871 411.3253,-257.3076 377.9469,-245.4194\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"378.7707,-241.9976 368.1761,-241.9394 376.4221,-248.5918 378.7707,-241.9976\"/>\n</g>\n<!-- 225 -->\n<g id=\"node10\" class=\"node\">\n<title>225</title>\n<path fill=\"#fef8f5\" stroke=\"#000000\" d=\"M648,-244C648,-244 493,-244 493,-244 487,-244 481,-238 481,-232 481,-232 481,-188 481,-188 481,-182 487,-176 493,-176 493,-176 648,-176 648,-176 654,-176 660,-182 660,-188 660,-188 660,-232 660,-232 660,-238 654,-244 648,-244\"/>\n<text text-anchor=\"middle\" x=\"570.5\" y=\"-228.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">sqft_above &lt;= &#45;0.371</text>\n<text text-anchor=\"middle\" x=\"570.5\" y=\"-213.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 37705184894.303</text>\n<text text-anchor=\"middle\" x=\"570.5\" y=\"-198.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 7674</text>\n<text text-anchor=\"middle\" x=\"570.5\" y=\"-183.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 526073.407</text>\n</g>\n<!-- 1&#45;&gt;225 -->\n<g id=\"edge9\" class=\"edge\">\n<title>1&#45;&gt;225</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M570.5,-279.9465C570.5,-271.776 570.5,-262.9318 570.5,-254.3697\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"574.0001,-254.13 570.5,-244.13 567.0001,-254.13 574.0001,-254.13\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<path fill=\"#fffdfb\" stroke=\"#000000\" d=\"M159,-140C159,-140 12,-140 12,-140 6,-140 0,-134 0,-128 0,-128 0,-84 0,-84 0,-78 6,-72 12,-72 12,-72 159,-72 159,-72 165,-72 171,-78 171,-84 171,-84 171,-128 171,-128 171,-134 165,-140 159,-140\"/>\n<text text-anchor=\"middle\" x=\"85.5\" y=\"-124.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">sqft_above &lt;= &#45;0.329</text>\n<text text-anchor=\"middle\" x=\"85.5\" y=\"-109.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 7650562346.505</text>\n<text text-anchor=\"middle\" x=\"85.5\" y=\"-94.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3269</text>\n<text text-anchor=\"middle\" x=\"85.5\" y=\"-79.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 271300.751</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M215.3046,-175.9465C196.893,-166.0252 176.6377,-155.1105 157.715,-144.9138\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"159.301,-141.7926 148.8374,-140.13 155.9803,-147.9549 159.301,-141.7926\"/>\n</g>\n<!-- 122 -->\n<g id=\"node7\" class=\"node\">\n<title>122</title>\n<path fill=\"#fefbf8\" stroke=\"#000000\" d=\"M356,-140C356,-140 201,-140 201,-140 195,-140 189,-134 189,-128 189,-128 189,-84 189,-84 189,-78 195,-72 201,-72 201,-72 356,-72 356,-72 362,-72 368,-78 368,-84 368,-84 368,-128 368,-128 368,-134 362,-140 356,-140\"/>\n<text text-anchor=\"middle\" x=\"278.5\" y=\"-124.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">lat &lt;= &#45;0.926</text>\n<text text-anchor=\"middle\" x=\"278.5\" y=\"-109.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 16819249722.049</text>\n<text text-anchor=\"middle\" x=\"278.5\" y=\"-94.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2076</text>\n<text text-anchor=\"middle\" x=\"278.5\" y=\"-79.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 382440.974</text>\n</g>\n<!-- 2&#45;&gt;122 -->\n<g id=\"edge6\" class=\"edge\">\n<title>2&#45;&gt;122</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M278.5,-175.9465C278.5,-167.776 278.5,-158.9318 278.5,-150.3697\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"282.0001,-150.13 278.5,-140.13 275.0001,-150.13 282.0001,-150.13\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<path fill=\"#c0c0c0\" stroke=\"#000000\" d=\"M64.5,-36C64.5,-36 34.5,-36 34.5,-36 28.5,-36 22.5,-30 22.5,-24 22.5,-24 22.5,-12 22.5,-12 22.5,-6 28.5,0 34.5,0 34.5,0 64.5,0 64.5,0 70.5,0 76.5,-6 76.5,-12 76.5,-12 76.5,-24 76.5,-24 76.5,-30 70.5,-36 64.5,-36\"/>\n<text text-anchor=\"middle\" x=\"49.5\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">(...)</text>\n</g>\n<!-- 3&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>3&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M71.5815,-71.9769C67.9977,-63.2167 64.1862,-53.8995 60.7564,-45.5157\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"63.968,-44.1222 56.9422,-36.192 57.4891,-46.7727 63.968,-44.1222\"/>\n</g>\n<!-- 63 -->\n<g id=\"node6\" class=\"node\">\n<title>63</title>\n<path fill=\"#c0c0c0\" stroke=\"#000000\" d=\"M136.5,-36C136.5,-36 106.5,-36 106.5,-36 100.5,-36 94.5,-30 94.5,-24 94.5,-24 94.5,-12 94.5,-12 94.5,-6 100.5,0 106.5,0 106.5,0 136.5,0 136.5,0 142.5,0 148.5,-6 148.5,-12 148.5,-12 148.5,-24 148.5,-24 148.5,-30 142.5,-36 136.5,-36\"/>\n<text text-anchor=\"middle\" x=\"121.5\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">(...)</text>\n</g>\n<!-- 3&#45;&gt;63 -->\n<g id=\"edge5\" class=\"edge\">\n<title>3&#45;&gt;63</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M99.4185,-71.9769C103.0023,-63.2167 106.8138,-53.8995 110.2436,-45.5157\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"113.5109,-46.7727 114.0578,-36.192 107.032,-44.1222 113.5109,-46.7727\"/>\n</g>\n<!-- 123 -->\n<g id=\"node8\" class=\"node\">\n<title>123</title>\n<path fill=\"#c0c0c0\" stroke=\"#000000\" d=\"M269.5,-36C269.5,-36 239.5,-36 239.5,-36 233.5,-36 227.5,-30 227.5,-24 227.5,-24 227.5,-12 227.5,-12 227.5,-6 233.5,0 239.5,0 239.5,0 269.5,0 269.5,0 275.5,0 281.5,-6 281.5,-12 281.5,-12 281.5,-24 281.5,-24 281.5,-30 275.5,-36 269.5,-36\"/>\n<text text-anchor=\"middle\" x=\"254.5\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">(...)</text>\n</g>\n<!-- 122&#45;&gt;123 -->\n<g id=\"edge7\" class=\"edge\">\n<title>122&#45;&gt;123</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M269.221,-71.9769C266.8838,-63.4071 264.4012,-54.3043 262.1538,-46.0638\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"265.4694,-44.9187 259.4614,-36.192 258.716,-46.7605 265.4694,-44.9187\"/>\n</g>\n<!-- 174 -->\n<g id=\"node9\" class=\"node\">\n<title>174</title>\n<path fill=\"#c0c0c0\" stroke=\"#000000\" d=\"M341.5,-36C341.5,-36 311.5,-36 311.5,-36 305.5,-36 299.5,-30 299.5,-24 299.5,-24 299.5,-12 299.5,-12 299.5,-6 305.5,0 311.5,0 311.5,0 341.5,0 341.5,0 347.5,0 353.5,-6 353.5,-12 353.5,-12 353.5,-24 353.5,-24 353.5,-30 347.5,-36 341.5,-36\"/>\n<text text-anchor=\"middle\" x=\"326.5\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">(...)</text>\n</g>\n<!-- 122&#45;&gt;174 -->\n<g id=\"edge8\" class=\"edge\">\n<title>122&#45;&gt;174</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M297.0581,-71.9769C301.8883,-63.1215 307.029,-53.6969 311.6404,-45.2427\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"314.8612,-46.6469 316.5771,-36.192 308.7159,-43.2949 314.8612,-46.6469\"/>\n</g>\n<!-- 226 -->\n<g id=\"node11\" class=\"node\">\n<title>226</title>\n<path fill=\"#fefaf6\" stroke=\"#000000\" d=\"M547,-140C547,-140 398,-140 398,-140 392,-140 386,-134 386,-128 386,-128 386,-84 386,-84 386,-78 392,-72 398,-72 398,-72 547,-72 547,-72 553,-72 559,-78 559,-84 559,-84 559,-128 559,-128 559,-134 553,-140 547,-140\"/>\n<text text-anchor=\"middle\" x=\"472.5\" y=\"-124.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">sqft_basement &lt;= 0.186</text>\n<text text-anchor=\"middle\" x=\"472.5\" y=\"-109.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 20237159939.23</text>\n<text text-anchor=\"middle\" x=\"472.5\" y=\"-94.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 4437</text>\n<text text-anchor=\"middle\" x=\"472.5\" y=\"-79.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 460427.101</text>\n</g>\n<!-- 225&#45;&gt;226 -->\n<g id=\"edge10\" class=\"edge\">\n<title>225&#45;&gt;226</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M538.4111,-175.9465C529.866,-166.8782 520.5387,-156.9799 511.6609,-147.5585\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"514.0663,-145.0076 504.661,-140.13 508.9717,-149.8082 514.0663,-145.0076\"/>\n</g>\n<!-- 337 -->\n<g id=\"node14\" class=\"node\">\n<title>337</title>\n<path fill=\"#fdf7f2\" stroke=\"#000000\" d=\"M744,-140C744,-140 589,-140 589,-140 583,-140 577,-134 577,-128 577,-128 577,-84 577,-84 577,-78 583,-72 589,-72 589,-72 744,-72 744,-72 750,-72 756,-78 756,-84 756,-84 756,-128 756,-128 756,-134 750,-140 744,-140\"/>\n<text text-anchor=\"middle\" x=\"666.5\" y=\"-124.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">waterfront &lt;= 5.516</text>\n<text text-anchor=\"middle\" x=\"666.5\" y=\"-109.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 47645027910.234</text>\n<text text-anchor=\"middle\" x=\"666.5\" y=\"-94.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3237</text>\n<text text-anchor=\"middle\" x=\"666.5\" y=\"-79.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 616055.694</text>\n</g>\n<!-- 225&#45;&gt;337 -->\n<g id=\"edge13\" class=\"edge\">\n<title>225&#45;&gt;337</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M601.934,-175.9465C610.3047,-166.8782 619.4416,-156.9799 628.1383,-147.5585\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"630.7844,-149.852 634.9954,-140.13 625.6407,-145.1041 630.7844,-149.852\"/>\n</g>\n<!-- 227 -->\n<g id=\"node12\" class=\"node\">\n<title>227</title>\n<path fill=\"#c0c0c0\" stroke=\"#000000\" d=\"M438.5,-36C438.5,-36 408.5,-36 408.5,-36 402.5,-36 396.5,-30 396.5,-24 396.5,-24 396.5,-12 396.5,-12 396.5,-6 402.5,0 408.5,0 408.5,0 438.5,0 438.5,0 444.5,0 450.5,-6 450.5,-12 450.5,-12 450.5,-24 450.5,-24 450.5,-30 444.5,-36 438.5,-36\"/>\n<text text-anchor=\"middle\" x=\"423.5\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">(...)</text>\n</g>\n<!-- 226&#45;&gt;227 -->\n<g id=\"edge11\" class=\"edge\">\n<title>226&#45;&gt;227</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M453.5553,-71.9769C448.5714,-63.0262 443.2638,-53.4941 438.5175,-44.9703\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"441.5524,-43.2261 433.6296,-36.192 435.4366,-46.6316 441.5524,-43.2261\"/>\n</g>\n<!-- 288 -->\n<g id=\"node13\" class=\"node\">\n<title>288</title>\n<path fill=\"#c0c0c0\" stroke=\"#000000\" d=\"M510.5,-36C510.5,-36 480.5,-36 480.5,-36 474.5,-36 468.5,-30 468.5,-24 468.5,-24 468.5,-12 468.5,-12 468.5,-6 474.5,0 480.5,0 480.5,0 510.5,0 510.5,0 516.5,0 522.5,-6 522.5,-12 522.5,-12 522.5,-24 522.5,-24 522.5,-30 516.5,-36 510.5,-36\"/>\n<text text-anchor=\"middle\" x=\"495.5\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">(...)</text>\n</g>\n<!-- 226&#45;&gt;288 -->\n<g id=\"edge12\" class=\"edge\">\n<title>226&#45;&gt;288</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M481.3924,-71.9769C483.6322,-63.4071 486.0114,-54.3043 488.1651,-46.0638\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"491.6028,-46.752 490.7453,-36.192 484.8303,-44.9819 491.6028,-46.752\"/>\n</g>\n<!-- 338 -->\n<g id=\"node15\" class=\"node\">\n<title>338</title>\n<path fill=\"#c0c0c0\" stroke=\"#000000\" d=\"M638.5,-36C638.5,-36 608.5,-36 608.5,-36 602.5,-36 596.5,-30 596.5,-24 596.5,-24 596.5,-12 596.5,-12 596.5,-6 602.5,0 608.5,0 608.5,0 638.5,0 638.5,0 644.5,0 650.5,-6 650.5,-12 650.5,-12 650.5,-24 650.5,-24 650.5,-30 644.5,-36 638.5,-36\"/>\n<text text-anchor=\"middle\" x=\"623.5\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">(...)</text>\n</g>\n<!-- 337&#45;&gt;338 -->\n<g id=\"edge14\" class=\"edge\">\n<title>337&#45;&gt;338</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M649.8751,-71.9769C645.548,-63.1215 640.9428,-53.6969 636.8118,-45.2427\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"639.9242,-43.6401 632.3892,-36.192 633.6349,-46.7133 639.9242,-43.6401\"/>\n</g>\n<!-- 399 -->\n<g id=\"node16\" class=\"node\">\n<title>399</title>\n<path fill=\"#c0c0c0\" stroke=\"#000000\" d=\"M710.5,-36C710.5,-36 680.5,-36 680.5,-36 674.5,-36 668.5,-30 668.5,-24 668.5,-24 668.5,-12 668.5,-12 668.5,-6 674.5,0 680.5,0 680.5,0 710.5,0 710.5,0 716.5,0 722.5,-6 722.5,-12 722.5,-12 722.5,-24 722.5,-24 722.5,-30 716.5,-36 710.5,-36\"/>\n<text text-anchor=\"middle\" x=\"695.5\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">(...)</text>\n</g>\n<!-- 337&#45;&gt;399 -->\n<g id=\"edge15\" class=\"edge\">\n<title>337&#45;&gt;399</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M677.7122,-71.9769C680.5677,-63.3119 683.6028,-54.102 686.3421,-45.7894\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"689.6991,-46.785 689.5049,-36.192 683.0508,-44.594 689.6991,-46.785\"/>\n</g>\n<!-- 427 -->\n<g id=\"node18\" class=\"node\">\n<title>427</title>\n<path fill=\"#fcf3ec\" stroke=\"#000000\" d=\"M1053.5,-244C1053.5,-244 889.5,-244 889.5,-244 883.5,-244 877.5,-238 877.5,-232 877.5,-232 877.5,-188 877.5,-188 877.5,-182 883.5,-176 889.5,-176 889.5,-176 1053.5,-176 1053.5,-176 1059.5,-176 1065.5,-182 1065.5,-188 1065.5,-188 1065.5,-232 1065.5,-232 1065.5,-238 1059.5,-244 1053.5,-244\"/>\n<text text-anchor=\"middle\" x=\"971.5\" y=\"-228.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">yr_built &lt;= 0.085</text>\n<text text-anchor=\"middle\" x=\"971.5\" y=\"-213.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 164036692201.576</text>\n<text text-anchor=\"middle\" x=\"971.5\" y=\"-198.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2804</text>\n<text text-anchor=\"middle\" x=\"971.5\" y=\"-183.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 863679.32</text>\n</g>\n<!-- 426&#45;&gt;427 -->\n<g id=\"edge17\" class=\"edge\">\n<title>426&#45;&gt;427</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M971.5,-279.9465C971.5,-271.776 971.5,-262.9318 971.5,-254.3697\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"975.0001,-254.13 971.5,-244.13 968.0001,-254.13 975.0001,-254.13\"/>\n</g>\n<!-- 630 -->\n<g id=\"node25\" class=\"node\">\n<title>630</title>\n<path fill=\"#fae6d7\" stroke=\"#000000\" d=\"M1362,-244C1362,-244 1207,-244 1207,-244 1201,-244 1195,-238 1195,-232 1195,-232 1195,-188 1195,-188 1195,-182 1201,-176 1207,-176 1207,-176 1362,-176 1362,-176 1368,-176 1374,-182 1374,-188 1374,-188 1374,-232 1374,-232 1374,-238 1368,-244 1362,-244\"/>\n<text text-anchor=\"middle\" x=\"1284.5\" y=\"-228.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">long &lt;= 0.095</text>\n<text text-anchor=\"middle\" x=\"1284.5\" y=\"-213.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 820818911262.96</text>\n<text text-anchor=\"middle\" x=\"1284.5\" y=\"-198.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 386</text>\n<text text-anchor=\"middle\" x=\"1284.5\" y=\"-183.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 1662117.51</text>\n</g>\n<!-- 426&#45;&gt;630 -->\n<g id=\"edge24\" class=\"edge\">\n<title>426&#45;&gt;630</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1065.8348,-282.6555C1103.5858,-270.1121 1147.0994,-255.6539 1185.3204,-242.9542\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1186.5306,-246.2403 1194.9169,-239.7656 1184.3233,-239.5974 1186.5306,-246.2403\"/>\n</g>\n<!-- 428 -->\n<g id=\"node19\" class=\"node\">\n<title>428</title>\n<path fill=\"#fbede2\" stroke=\"#000000\" d=\"M950.5,-140C950.5,-140 786.5,-140 786.5,-140 780.5,-140 774.5,-134 774.5,-128 774.5,-128 774.5,-84 774.5,-84 774.5,-78 780.5,-72 786.5,-72 786.5,-72 950.5,-72 950.5,-72 956.5,-72 962.5,-78 962.5,-84 962.5,-84 962.5,-128 962.5,-128 962.5,-134 956.5,-140 950.5,-140\"/>\n<text text-anchor=\"middle\" x=\"868.5\" y=\"-124.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">sqft_living15 &lt;= 1.378</text>\n<text text-anchor=\"middle\" x=\"868.5\" y=\"-109.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 260396487545.851</text>\n<text text-anchor=\"middle\" x=\"868.5\" y=\"-94.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 483</text>\n<text text-anchor=\"middle\" x=\"868.5\" y=\"-79.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 1233555.337</text>\n</g>\n<!-- 427&#45;&gt;428 -->\n<g id=\"edge18\" class=\"edge\">\n<title>427&#45;&gt;428</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M937.7739,-175.9465C928.7039,-166.7884 918.7955,-156.7838 909.3819,-147.2788\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"911.8255,-144.7723 902.3018,-140.13 906.8519,-149.6981 911.8255,-144.7723\"/>\n</g>\n<!-- 525 -->\n<g id=\"node22\" class=\"node\">\n<title>525</title>\n<path fill=\"#fdf4ee\" stroke=\"#000000\" d=\"M1156.5,-140C1156.5,-140 992.5,-140 992.5,-140 986.5,-140 980.5,-134 980.5,-128 980.5,-128 980.5,-84 980.5,-84 980.5,-78 986.5,-72 992.5,-72 992.5,-72 1156.5,-72 1156.5,-72 1162.5,-72 1168.5,-78 1168.5,-84 1168.5,-84 1168.5,-128 1168.5,-128 1168.5,-134 1162.5,-140 1156.5,-140\"/>\n<text text-anchor=\"middle\" x=\"1074.5\" y=\"-124.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">lat &lt;= &#45;0.24</text>\n<text text-anchor=\"middle\" x=\"1074.5\" y=\"-109.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 109589865059.151</text>\n<text text-anchor=\"middle\" x=\"1074.5\" y=\"-94.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2321</text>\n<text text-anchor=\"middle\" x=\"1074.5\" y=\"-79.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 786708.136</text>\n</g>\n<!-- 427&#45;&gt;525 -->\n<g id=\"edge21\" class=\"edge\">\n<title>427&#45;&gt;525</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1005.2261,-175.9465C1014.2961,-166.7884 1024.2045,-156.7838 1033.6181,-147.2788\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1036.1481,-149.6981 1040.6982,-140.13 1031.1745,-144.7723 1036.1481,-149.6981\"/>\n</g>\n<!-- 429 -->\n<g id=\"node20\" class=\"node\">\n<title>429</title>\n<path fill=\"#c0c0c0\" stroke=\"#000000\" d=\"M842.5,-36C842.5,-36 812.5,-36 812.5,-36 806.5,-36 800.5,-30 800.5,-24 800.5,-24 800.5,-12 800.5,-12 800.5,-6 806.5,0 812.5,0 812.5,0 842.5,0 842.5,0 848.5,0 854.5,-6 854.5,-12 854.5,-12 854.5,-24 854.5,-24 854.5,-30 848.5,-36 842.5,-36\"/>\n<text text-anchor=\"middle\" x=\"827.5\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">(...)</text>\n</g>\n<!-- 428&#45;&gt;429 -->\n<g id=\"edge19\" class=\"edge\">\n<title>428&#45;&gt;429</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M852.6483,-71.9769C848.5669,-63.2167 844.2259,-53.8995 840.3198,-45.5157\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"843.3716,-43.7783 835.9758,-36.192 837.0265,-46.7346 843.3716,-43.7783\"/>\n</g>\n<!-- 466 -->\n<g id=\"node21\" class=\"node\">\n<title>466</title>\n<path fill=\"#c0c0c0\" stroke=\"#000000\" d=\"M914.5,-36C914.5,-36 884.5,-36 884.5,-36 878.5,-36 872.5,-30 872.5,-24 872.5,-24 872.5,-12 872.5,-12 872.5,-6 878.5,0 884.5,0 884.5,0 914.5,0 914.5,0 920.5,0 926.5,-6 926.5,-12 926.5,-12 926.5,-24 926.5,-24 926.5,-30 920.5,-36 914.5,-36\"/>\n<text text-anchor=\"middle\" x=\"899.5\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">(...)</text>\n</g>\n<!-- 428&#45;&gt;466 -->\n<g id=\"edge20\" class=\"edge\">\n<title>428&#45;&gt;466</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M880.4854,-71.9769C883.5379,-63.3119 886.7823,-54.102 889.7105,-45.7894\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"893.07,-46.7868 893.0915,-36.192 886.4677,-44.4609 893.07,-46.7868\"/>\n</g>\n<!-- 526 -->\n<g id=\"node23\" class=\"node\">\n<title>526</title>\n<path fill=\"#c0c0c0\" stroke=\"#000000\" d=\"M1050.5,-36C1050.5,-36 1020.5,-36 1020.5,-36 1014.5,-36 1008.5,-30 1008.5,-24 1008.5,-24 1008.5,-12 1008.5,-12 1008.5,-6 1014.5,0 1020.5,0 1020.5,0 1050.5,0 1050.5,0 1056.5,0 1062.5,-6 1062.5,-12 1062.5,-12 1062.5,-24 1062.5,-24 1062.5,-30 1056.5,-36 1050.5,-36\"/>\n<text text-anchor=\"middle\" x=\"1035.5\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">(...)</text>\n</g>\n<!-- 525&#45;&gt;526 -->\n<g id=\"edge22\" class=\"edge\">\n<title>525&#45;&gt;526</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1059.4216,-71.9769C1055.5392,-63.2167 1051.41,-53.8995 1047.6945,-45.5157\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1050.814,-43.9162 1043.5623,-36.192 1044.4143,-46.7525 1050.814,-43.9162\"/>\n</g>\n<!-- 569 -->\n<g id=\"node24\" class=\"node\">\n<title>569</title>\n<path fill=\"#c0c0c0\" stroke=\"#000000\" d=\"M1122.5,-36C1122.5,-36 1092.5,-36 1092.5,-36 1086.5,-36 1080.5,-30 1080.5,-24 1080.5,-24 1080.5,-12 1080.5,-12 1080.5,-6 1086.5,0 1092.5,0 1092.5,0 1122.5,0 1122.5,0 1128.5,0 1134.5,-6 1134.5,-12 1134.5,-12 1134.5,-24 1134.5,-24 1134.5,-30 1128.5,-36 1122.5,-36\"/>\n<text text-anchor=\"middle\" x=\"1107.5\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">(...)</text>\n</g>\n<!-- 525&#45;&gt;569 -->\n<g id=\"edge23\" class=\"edge\">\n<title>525&#45;&gt;569</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1087.2587,-71.9769C1090.508,-63.3119 1093.9618,-54.102 1097.079,-45.7894\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1100.4439,-46.7842 1100.678,-36.192 1093.8896,-44.3263 1100.4439,-46.7842\"/>\n</g>\n<!-- 631 -->\n<g id=\"node26\" class=\"node\">\n<title>631</title>\n<path fill=\"#f8dcc8\" stroke=\"#000000\" d=\"M1370.5,-140C1370.5,-140 1198.5,-140 1198.5,-140 1192.5,-140 1186.5,-134 1186.5,-128 1186.5,-128 1186.5,-84 1186.5,-84 1186.5,-78 1192.5,-72 1198.5,-72 1198.5,-72 1370.5,-72 1370.5,-72 1376.5,-72 1382.5,-78 1382.5,-84 1382.5,-84 1382.5,-128 1382.5,-128 1382.5,-134 1376.5,-140 1370.5,-140\"/>\n<text text-anchor=\"middle\" x=\"1284.5\" y=\"-124.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">sqft_above &lt;= 5.339</text>\n<text text-anchor=\"middle\" x=\"1284.5\" y=\"-109.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 1229737689482.953</text>\n<text text-anchor=\"middle\" x=\"1284.5\" y=\"-94.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 146</text>\n<text text-anchor=\"middle\" x=\"1284.5\" y=\"-79.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 2250994.692</text>\n</g>\n<!-- 630&#45;&gt;631 -->\n<g id=\"edge25\" class=\"edge\">\n<title>630&#45;&gt;631</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1284.5,-175.9465C1284.5,-167.776 1284.5,-158.9318 1284.5,-150.3697\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1288.0001,-150.13 1284.5,-140.13 1281.0001,-150.13 1288.0001,-150.13\"/>\n</g>\n<!-- 692 -->\n<g id=\"node29\" class=\"node\">\n<title>692</title>\n<path fill=\"#fbece0\" stroke=\"#000000\" d=\"M1576.5,-140C1576.5,-140 1412.5,-140 1412.5,-140 1406.5,-140 1400.5,-134 1400.5,-128 1400.5,-128 1400.5,-84 1400.5,-84 1400.5,-78 1406.5,-72 1412.5,-72 1412.5,-72 1576.5,-72 1576.5,-72 1582.5,-72 1588.5,-78 1588.5,-84 1588.5,-84 1588.5,-128 1588.5,-128 1588.5,-134 1582.5,-140 1576.5,-140\"/>\n<text text-anchor=\"middle\" x=\"1494.5\" y=\"-124.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">waterfront &lt;= 5.516</text>\n<text text-anchor=\"middle\" x=\"1494.5\" y=\"-109.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mse = 232773058614.813</text>\n<text text-anchor=\"middle\" x=\"1494.5\" y=\"-94.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 240</text>\n<text text-anchor=\"middle\" x=\"1494.5\" y=\"-79.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = 1303883.892</text>\n</g>\n<!-- 630&#45;&gt;692 -->\n<g id=\"edge28\" class=\"edge\">\n<title>630&#45;&gt;692</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1353.2619,-175.9465C1373.4765,-165.9354 1395.7336,-154.9129 1416.4828,-144.6371\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1418.1757,-147.7045 1425.5837,-140.13 1415.0691,-141.4316 1418.1757,-147.7045\"/>\n</g>\n<!-- 632 -->\n<g id=\"node27\" class=\"node\">\n<title>632</title>\n<path fill=\"#c0c0c0\" stroke=\"#000000\" d=\"M1263.5,-36C1263.5,-36 1233.5,-36 1233.5,-36 1227.5,-36 1221.5,-30 1221.5,-24 1221.5,-24 1221.5,-12 1221.5,-12 1221.5,-6 1227.5,0 1233.5,0 1233.5,0 1263.5,0 1263.5,0 1269.5,0 1275.5,-6 1275.5,-12 1275.5,-12 1275.5,-24 1275.5,-24 1275.5,-30 1269.5,-36 1263.5,-36\"/>\n<text text-anchor=\"middle\" x=\"1248.5\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">(...)</text>\n</g>\n<!-- 631&#45;&gt;632 -->\n<g id=\"edge26\" class=\"edge\">\n<title>631&#45;&gt;632</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1270.5815,-71.9769C1266.9977,-63.2167 1263.1862,-53.8995 1259.7564,-45.5157\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1262.968,-44.1222 1255.9422,-36.192 1256.4891,-46.7727 1262.968,-44.1222\"/>\n</g>\n<!-- 681 -->\n<g id=\"node28\" class=\"node\">\n<title>681</title>\n<path fill=\"#c0c0c0\" stroke=\"#000000\" d=\"M1335.5,-36C1335.5,-36 1305.5,-36 1305.5,-36 1299.5,-36 1293.5,-30 1293.5,-24 1293.5,-24 1293.5,-12 1293.5,-12 1293.5,-6 1299.5,0 1305.5,0 1305.5,0 1335.5,0 1335.5,0 1341.5,0 1347.5,-6 1347.5,-12 1347.5,-12 1347.5,-24 1347.5,-24 1347.5,-30 1341.5,-36 1335.5,-36\"/>\n<text text-anchor=\"middle\" x=\"1320.5\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">(...)</text>\n</g>\n<!-- 631&#45;&gt;681 -->\n<g id=\"edge27\" class=\"edge\">\n<title>631&#45;&gt;681</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1298.4185,-71.9769C1302.0023,-63.2167 1305.8138,-53.8995 1309.2436,-45.5157\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1312.5109,-46.7727 1313.0578,-36.192 1306.032,-44.1222 1312.5109,-46.7727\"/>\n</g>\n<!-- 693 -->\n<g id=\"node30\" class=\"node\">\n<title>693</title>\n<path fill=\"#c0c0c0\" stroke=\"#000000\" d=\"M1473.5,-36C1473.5,-36 1443.5,-36 1443.5,-36 1437.5,-36 1431.5,-30 1431.5,-24 1431.5,-24 1431.5,-12 1431.5,-12 1431.5,-6 1437.5,0 1443.5,0 1443.5,0 1473.5,0 1473.5,0 1479.5,0 1485.5,-6 1485.5,-12 1485.5,-12 1485.5,-24 1485.5,-24 1485.5,-30 1479.5,-36 1473.5,-36\"/>\n<text text-anchor=\"middle\" x=\"1458.5\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">(...)</text>\n</g>\n<!-- 692&#45;&gt;693 -->\n<g id=\"edge29\" class=\"edge\">\n<title>692&#45;&gt;693</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1480.5815,-71.9769C1476.9977,-63.2167 1473.1862,-53.8995 1469.7564,-45.5157\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1472.968,-44.1222 1465.9422,-36.192 1466.4891,-46.7727 1472.968,-44.1222\"/>\n</g>\n<!-- 734 -->\n<g id=\"node31\" class=\"node\">\n<title>734</title>\n<path fill=\"#c0c0c0\" stroke=\"#000000\" d=\"M1545.5,-36C1545.5,-36 1515.5,-36 1515.5,-36 1509.5,-36 1503.5,-30 1503.5,-24 1503.5,-24 1503.5,-12 1503.5,-12 1503.5,-6 1509.5,0 1515.5,0 1515.5,0 1545.5,0 1545.5,0 1551.5,0 1557.5,-6 1557.5,-12 1557.5,-12 1557.5,-24 1557.5,-24 1557.5,-30 1551.5,-36 1545.5,-36\"/>\n<text text-anchor=\"middle\" x=\"1530.5\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">(...)</text>\n</g>\n<!-- 692&#45;&gt;734 -->\n<g id=\"edge30\" class=\"edge\">\n<title>692&#45;&gt;734</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1508.4185,-71.9769C1512.0023,-63.2167 1515.8138,-53.8995 1519.2436,-45.5157\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1522.5109,-46.7727 1523.0578,-36.192 1516.032,-44.1222 1522.5109,-46.7727\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPMnA1w-bweB",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}